---
layout: post
categories: Research
date: Tue Jun  6 10:43:15 2017
title: "Semantic Segmentation using Adversarial Networks - Notes"
tag:
- GAN
- segmentation
---

This paper utilized Generative Adversarial Network(GAN) to learn higher-order inconsistencies between ground truth sementation maps and the ones generated by sementation net.

### Motivation

0. Simply using CNN to do segmentation means independently predicting class label for each pixel, at least during training, which is definitely incorrect.
1. Conditional Markov random fields(CRFs) can enforce spatial contiguity in the output label maps to some extent, but only pairwise potentials are considered.
2. Existing work to discover higher-order potentials usually is limited to a very specific classes.
3. Therefore, the author came up with a method to enforce higher-order consistency in the ouput label map without being limited to special classes.

### Adversatial training

0. **Loss Function**:

    $$
    l(\theta_s, \theta_a) = \sum_{n=1}^{N}l_{mce}(s(x_n), y_n) - \lambda[l_{bce}(a(x_n, y_n),1) + l_{bce}(a(x_n,s(x_n)),0)]
    $$

    Where $\theta_s$ and $\theta_a$ represent parameters of sementation net and adversarial net, $a(x,y) \in [0,1]$ is the probability that adversarial model predicts that $y$ is the ground-truth label map of $x$.

    The loss function is composed of two elements:

    - First one: muli-class cross-entropy loss to encourage the sementation model to predict the right class label at each pixel independently.
    - Second one: binary cross-entropy loss to enforce the discriminator being able to distinguish the output of segmentation net and the ground truth label map.

1. **Network Struction**:
    
    ![overview of the proposed approach](https://cl.ly/2p1q3a301U0p/Image%202017-06-06%20at%2011.25.15%20AM.png)

    Two separate branches generate ground-truth label map and output of segmentation net, which have roughly the same number of channels to avoid one signal dominates the other. The ground-truth maps are down-sampled to match the size of output of segmentation net, and fed into the adversarial network in a 1-hot encoding way if selected. 

    For **Stanford Background dataset**, the inputs to adversarial network is the original RGB image and the corresponding label map, the label map is either the gorund-truth one or generated one by the segmentation net. The prediction of adversarial net is whether the label map is the ground-truth of RGB frame.

    For **Pascal VOC 2012 dataset**, the author explored three variants for the input: *Basic*, *Product* and *Scaling*.

    - *Basic*: The only input is label map, either ground-truth one or probability map generated by the segmentation network. However it's easy to overfit because the difference in two kinds of label map.
    - *Product*: The only input is the product result of label map and input image, which is an input with 3C channels(C is the number of classes).
    - *Scaling*: Replace the 1-hot coding of the ground-truth label map with distrbutions as similar as possible to the distributions generated by the sementation network, while with a least mass value $\tau$. Then use the newly generated map as input(?). <span class="evidence">Not sure!!!</span>

    Then the authors zero-out all values at the spatial positons and corresponding gradient values of unlabeled pixels in all label maps.

2. **Performance**

    Achieve some improvement on both two datasets, but the paper dosn't provide any comparison results with other methods on the same datasets.








